{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wPvkV7CHpLFc",
        "outputId": "52f3dee0-f4a4-4a0f-bc86-0bee991fb973"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Credit Risk Data Loaded.\n",
            "Rows: 1000\n",
            "Target Distribution (1=Good, 2=Bad):\n",
            "Target\n",
            "1    700\n",
            "2    300\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load German Credit Data directly from the UCI Machine Learning Repository\n",
        "url = \"http://archive.ics.uci.edu/ml/machine-learning-databases/statlog/german/german.data\"\n",
        "\n",
        "# The dataset has no headers, so we define them manually\n",
        "# This data tells us: Age, Credit History, Purpose, Loan Amount... and did they Default?\n",
        "columns = [\n",
        "    'Status_Checking', 'Duration_Month', 'Credit_History', 'Purpose',\n",
        "    'Credit_Amount', 'Savings', 'Employment_Since', 'Installment_Rate',\n",
        "    'Status_Sex', 'Guarantors', 'Residence_Since', 'Property', 'Age',\n",
        "    'Other_Plans', 'Housing', 'Credits_Existing', 'Job', 'Liable_People',\n",
        "    'Telephone', 'Foreign_Worker', 'Target' # 1 = Good, 2 = Bad (Default)\n",
        "]\n",
        "\n",
        "# Separator is a space, not a comma\n",
        "df_credit = pd.read_csv(url, sep=' ', names=columns)\n",
        "\n",
        "print(\"Credit Risk Data Loaded.\")\n",
        "print(f\"Rows: {len(df_credit)}\")\n",
        "print(\"Target Distribution (1=Good, 2=Bad):\")\n",
        "print(df_credit['Target'].value_counts())"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "\n",
        "# 1. Clean the Data\n",
        "# The dataset uses '1' for Good and '2' for Bad. Let's make it standard: 0 = Good, 1 = Bad (Default)\n",
        "df_credit['Target'] = df_credit['Target'].map({1: 0, 2: 1})\n",
        "\n",
        "# Convert text columns (e.g., \"History: Critical\") into numbers (0s and 1s)\n",
        "# This creates new columns like \"Purpose_Car\", \"Purpose_Education\", etc.\n",
        "df_clean = pd.get_dummies(df_credit, drop_first=True)\n",
        "\n",
        "# 2. Split the Data\n",
        "# X = All the data about the person (Age, Loan Amount, Job...)\n",
        "# y = The Target (Did they default?)\n",
        "X = df_clean.drop('Target', axis=1)\n",
        "y = df_clean['Target']\n",
        "\n",
        "# We hide 20% of the data to test the model later\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# 3. Train the Model (Random Forest)\n",
        "print(\"Training the Fintech Risk Engine...\")\n",
        "rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "rf_model.fit(X_train, y_train)\n",
        "\n",
        "print(\"Training Complete. The model has learned the patterns of default.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YEBV_Ltvp3sL",
        "outputId": "5c936a62-259b-4176-8359-af9e5b0827e2"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training the Fintech Risk Engine...\n",
            "Training Complete. The model has learned the patterns of default.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Predict\n",
        "y_pred = rf_model.predict(X_test)\n",
        "\n",
        "# 2. Evaluate\n",
        "print(\"=== RISK MODEL PERFORMANCE REPORT ===\\n\")\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "# 3. The Money Metrics (Confusion Matrix)\n",
        "tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
        "\n",
        "print(\"--- FINANCIAL IMPACT ANALYSIS ---\")\n",
        "print(f\"Correctly Approved (True Negatives): {tn} (We made profit)\")\n",
        "print(f\"Correctly Rejected (True Positives): {tp} (We saved money)\")\n",
        "print(f\"False Alarms (False Positives): {fp} (We rejected a good customer - Opportunity Cost)\")\n",
        "print(f\"CATASTROPHIC FAILURES (False Negatives): {fn} (We approved a defaulter - Direct Loss)\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3l_4FSOOu7u4",
        "outputId": "dd1e5756-e648-4a2c-9d63-28835756c34b"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== RISK MODEL PERFORMANCE REPORT ===\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.77      0.91      0.83       141\n",
            "           1       0.62      0.34      0.44        59\n",
            "\n",
            "    accuracy                           0.74       200\n",
            "   macro avg       0.70      0.63      0.64       200\n",
            "weighted avg       0.73      0.74      0.72       200\n",
            "\n",
            "--- FINANCIAL IMPACT ANALYSIS ---\n",
            "Correctly Approved (True Negatives): 129 (We made profit)\n",
            "Correctly Rejected (True Positives): 20 (We saved money)\n",
            "False Alarms (False Positives): 12 (We rejected a good customer - Opportunity Cost)\n",
            "CATASTROPHIC FAILURES (False Negatives): 39 (We approved a defaulter - Direct Loss)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Retrain with \"Balanced\" Weights\n",
        "# This tells the model to penalize mistakes on the \"Bad\" class more heavily\n",
        "print(\"Retraining with Heavy Penalties for Defaults...\")\n",
        "rf_model_weighted = RandomForestClassifier(n_estimators=100, class_weight='balanced', random_state=42)\n",
        "rf_model_weighted.fit(X_train, y_train)\n",
        "\n",
        "# 2. Predict Probabilities (Not just Yes/No)\n",
        "# Instead of a hard \"0 or 1\", we get the % risk (e.g., 0.45 chance of default)\n",
        "y_probs = rf_model_weighted.predict_proba(X_test)[:, 1]\n",
        "\n",
        "# 3. Move the Goalposts (Threshold Tuning)\n",
        "# Standard models use 0.50 (50%). We will be stricter.\n",
        "# If the model thinks there is >30% chance of default, we REJECT (Label it 1).\n",
        "custom_threshold = 0.30\n",
        "y_pred_strict = (y_probs > custom_threshold).astype(int)\n",
        "\n",
        "# 4. The New Scorecard\n",
        "print(\"\\n=== STRICT RISK MODEL REPORT (Threshold: 30%) ===\")\n",
        "tn, fp, fn, tp = confusion_matrix(y_test, y_pred_strict).ravel()\n",
        "\n",
        "print(f\"Correctly Approved (True Negatives): {tn}\")\n",
        "print(f\"Correctly Rejected (True Positives): {tp} (These are the losses we avoided!)\")\n",
        "print(f\"False Alarms (False Positives): {fp} (Good customers we annoyed - acceptable loss)\")\n",
        "print(f\"CATASTROPHIC FAILURES (False Negatives): {fn} (Did this number go down?)\")\n",
        "\n",
        "# Check the new Recall score\n",
        "from sklearn.metrics import recall_score\n",
        "new_recall = recall_score(y_test, y_pred_strict)\n",
        "print(f\"\\nNew Recall Score: {new_recall:.2f} (Target: > 0.80)\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CoXD2YfL6JY8",
        "outputId": "a87523c7-edb7-422d-a087-6cc8239078f4"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Retraining with Heavy Penalties for Defaults...\n",
            "\n",
            "=== STRICT RISK MODEL REPORT (Threshold: 30%) ===\n",
            "Correctly Approved (True Negatives): 93\n",
            "Correctly Rejected (True Positives): 47 (These are the losses we avoided!)\n",
            "False Alarms (False Positives): 48 (Good customers we annoyed - acceptable loss)\n",
            "CATASTROPHIC FAILURES (False Negatives): 12 (Did this number go down?)\n",
            "\n",
            "New Recall Score: 0.80 (Target: > 0.80)\n"
          ]
        }
      ]
    }
  ]
}